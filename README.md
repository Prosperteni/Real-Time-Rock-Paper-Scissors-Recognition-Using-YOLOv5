# Real-Time-Rock-Paper-Scissors-Recognition-Using-YOLOv5
Real-Time Rock, Paper, Scissors Recognition Using YOLOv5-Lite

This project is a real-time hand gesture recognition system built with **YOLOv5-Lite**, capable of detecting and classifying rock, paper, and scissors using a webcam feed.

> ğŸ“ This was my official school project, and it means a lot to me â€” it marks my hands-on dive into real-world AI development. I'm passionate about building smart systems, and this project reflects my interest in solving interactive problems using machine learning.

---

## ğŸ“Œ Features

- âœ… Real-time detection of rock, paper, and scissors gestures
- ğŸ“¸ Custom dataset creation with varied lighting and angles
- ğŸ·ï¸ Manual image annotation using LabelImg and Label Studio
- ğŸ’» Model trained locally on a personal laptop (YOLOv5-Lite, mAP@0.5 = 0.96)
- âš¡ Real-time webcam detection with OpenCV (20â€“30 FPS)
- ğŸ“„ Full documentation of setup, training, troubleshooting, and deployment

---

## ğŸ› ï¸ Tools & Technologies

- Python 3.12  
- PyTorch  
- YOLOv5 / YOLOv5-Lite  
- OpenCV  
- LabelImg, Label Studio  
- Anaconda (virtual environment)  
- Windows (training environment)

---

## ğŸ“‚ Project Structure

rock-paper-scissors-yolov5/
datasets/
â”œâ”€â”€ ğŸ“‚ images/
â”‚   â”œâ”€â”€ ğŸ“‚ train/
â”‚   â””â”€â”€ ğŸ“‚ validation/
â”‚
â”œâ”€â”€ ğŸ“‚ labels/
â”‚   â”œâ”€â”€ ğŸ“‚ train/
â”‚   â””â”€â”€ ğŸ“‚ validation/
â”‚
â”œâ”€â”€ classes.txt               # Class names (e.g., rock, paper, scissors)
â””â”€â”€ data.yaml                 # Dataset config file for YOLOv5
â”œâ”€â”€ ğŸ“‚ models/
â”‚   â””â”€â”€ best.pt                # Trained model weights
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â”œâ”€â”€ train.py               # Training script
â”‚   â”œâ”€â”€ detect.py              # Detection script
â”‚   â”œâ”€â”€ split.py               # Optional: dataset splitter
â”‚   â”œâ”€â”€ gen-data-yaml.py       # Script to generate data.yaml
